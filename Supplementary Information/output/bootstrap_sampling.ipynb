{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bootstrap Sampling\n",
    "\n",
    "This script:\n",
    "- Identifies all valid observations (e.g., the valid border edges)\n",
    "- Creates an empty array for camp exposure values\n",
    "- Generates a random sample of n with sampling with replacement of original data\n",
    "- Adds the camp to the random sample (i.e., n+1 as sample size)\n",
    "- Normalizes data within each random sample using existing methodology\n",
    "- Appends the exposure value to the sample array\n",
    "- Saves output observations to the full bootstrap object\n",
    "\n",
    "\n",
    "The structure of the sample is recorded as:\n",
    "\n",
    "```\n",
    "{ 'Kakuma': [0.65, 0.78,...],\n",
    "  'Bidi Bidi': [0.62, 0.64,...],\n",
    "  ...\n",
    "  }\n",
    "```\n",
    "\n",
    "\n",
    "- These observations are then sorted, and used as the basis for the upper and lower bound intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load in the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_data_winsorized = pd.read_csv(\"aggregated_base_data.csv\")\n",
    "camp_data = pd.read_csv(\"camp_data_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define primary index construction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_variables_update = [\n",
    "    'seasonal_precipitation_max',\n",
    "    'pdsi',\n",
    "    'temperature_anomaly',\n",
    "    'daytime_maximum_temperature',\n",
    "    'specific_humidity',\n",
    "    'precipitation',\n",
    "    'interannual_coefficient_variation_precipitation',\n",
    "    'ssm',\n",
    "    'slope',\n",
    "    'flow_accumulation',\n",
    "    'friction',\n",
    "]\n",
    "\n",
    "variables_min_max = [\n",
    "    'coefficient_variation_ndvi',\n",
    "    'daytime_maximum_temperature',\n",
    "    'evi_change',\n",
    "    'flow_accumulation',\n",
    "    'friction',\n",
    "    'interannual_coefficient_variation_precipitation',\n",
    "    'pdsi',\n",
    "    'population',\n",
    "    'precipitation',\n",
    "    'seasonal_precipitation_max',\n",
    "    'slope',\n",
    "    'specific_humidity',\n",
    "    'temperature_anomaly',\n",
    "]\n",
    "\n",
    "variables_max_min = ['ssm', 'susm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_winsorized_data(dataset, min_max, max_min):\n",
    "    dataset[min_max] = dataset[min_max].transform(lambda x: ((x - x.min()) / (x.max() - x.min())))\n",
    "    dataset[max_min] = dataset[max_min].transform(lambda x: ((x.max() - x) / (x.max() - x.min())))\n",
    "    return dataset\n",
    "\n",
    "def generate_index(index_vars, normalized_dataset):\n",
    "    normalized_dataset['exposure'] = normalized_dataset.loc[:, index_vars].sum(axis=1)\n",
    "    normalized_dataset['exposure'] = normalized_dataset['exposure'].div(len(index_vars))\n",
    "    normalized_dataset['rank'] = normalized_dataset['exposure'].rank(method=\"dense\", ascending=False)\n",
    "    normalized_dataset['percentile'] = normalized_dataset['exposure'].rank(pct=True)\n",
    "    return normalized_dataset\n",
    "\n",
    "def generate_min_max_exposure(index_vars, normalized_input):\n",
    "    max_list = list(normalized_input.loc[:, index_vars].sum(axis=1))\n",
    "    max_list = [x / len(index_vars) for x in max_list]\n",
    "    min_list = list(normalized_input.loc[:, index_vars].sum(axis=1))\n",
    "    min_list = [x / len(index_vars) for x in min_list]\n",
    "\n",
    "    for var in index_vars:\n",
    "        current_index_vars = list(index_vars)\n",
    "        current_index_vars.remove(var)\n",
    "        current_list = list(normalized_input.loc[:, current_index_vars].sum(axis=1))\n",
    "        current_list = [x / len(current_index_vars) for x in current_list]\n",
    "\n",
    "        max_list = np.maximum(np.array(max_list), np.array(current_list)).tolist()\n",
    "        min_list = np.minimum(np.array(min_list), np.array(current_list)).tolist()\n",
    "\n",
    "    return min_list, max_list\n",
    "\n",
    "def iterate_min_max_exposure(normalized_dataset):\n",
    "\n",
    "    min_list_out, max_list_out = generate_min_max_exposure(index_variables_update, normalized_dataset)\n",
    "    min_max_index_data_update = normalized_dataset.copy(deep=True)\n",
    "    min_max_index_data_update['min_exposure'] = min_list_out\n",
    "    min_max_index_data_update['max_exposure'] = max_list_out\n",
    "\n",
    "    min_max_index_data_update['min_rank'] = min_max_index_data_update['min_exposure'].rank(method=\"dense\", ascending=False)\n",
    "    min_max_index_data_update['min_percentile'] = min_max_index_data_update['min_exposure'].rank(pct=True)\n",
    "\n",
    "    min_max_index_data_update['max_rank'] = min_max_index_data_update['max_exposure'].rank(method=\"dense\", ascending=False)\n",
    "    min_max_index_data_update['max_percentile'] = min_max_index_data_update['max_exposure'].rank(pct=True)\n",
    "    return min_max_index_data_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gen_normalized_exposure_indices_bootstrap(camp):\n",
    "    bootstrap_exposure = []\n",
    "    dc_final_data_winsorized = final_data_winsorized.copy(deep=True)\n",
    "    for i in range(10000):\n",
    "        active_subset = final_data_winsorized.loc[(final_data_winsorized['camp_name'] == camp)]\n",
    "        edge_options = active_subset[\"edge\"].to_list()[0]\n",
    "        deep_copy_final_data_winsorized = dc_final_data_winsorized[dc_final_data_winsorized['edge'].isin(ast.literal_eval(edge_options))].copy(deep=True)\n",
    "        random_sample = deep_copy_final_data_winsorized.sample(frac=1, replace=True)\n",
    "\n",
    "        active_subset = pd.concat([active_subset, random_sample])\n",
    "\n",
    "        normalized_data = normalize_winsorized_data(active_subset.copy(deep=True), variables_min_max, variables_max_min)\n",
    "        index_data_update = generate_index(index_variables_update, normalized_data.copy(deep=True))\n",
    "        index_data_update = iterate_min_max_exposure(index_data_update.copy(deep=True))\n",
    "        bootstrap_exposure.append(index_data_update.loc[(index_data_update[\"camp_name\"] == camp)][\"percentile\"].values[0])\n",
    "\n",
    "    return bootstrap_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gen_camp_exposure_bootstrap_json():\n",
    "    all_bootstrap_data = {}\n",
    "    for camp in camp_data[\"camp_name\"].to_list():\n",
    "        all_bootstrap_data[camp] = gen_normalized_exposure_indices_bootstrap(camp)\n",
    "    return all_bootstrap_data\n",
    "output = gen_camp_exposure_bootstrap_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in output:\n",
    "    fig = px.histogram(output[i], title=i)\n",
    "    fig.update_xaxes(matches=None)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('bootstrap_sample_data_tenk.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "median = []\n",
    "lower_025 = []\n",
    "top_025 = []\n",
    "camp_array = []\n",
    "\n",
    "for camp in output:\n",
    "    lower_index = round(10000 * 0.025) - 1\n",
    "    median_index = round(10000 / 2) - 1\n",
    "    upper_index = 10000 - round(10000 * 0.025) - 1\n",
    "\n",
    "    output[camp].sort()\n",
    "    lower_025.append(output[camp][lower_index])\n",
    "    median.append(output[camp][median_index])\n",
    "    top_025.append(output[camp][upper_index])\n",
    "    camp_array.append(camp)\n",
    "\n",
    "\n",
    "bootstrap_data = []\n",
    "for item in zip(camp_array, lower_025, median, top_025):\n",
    "    bootstrap_data.append(item)\n",
    "\n",
    "bootstrap_df = pd.DataFrame(bootstrap_data, columns=[\n",
    "    \"camp_name\",\n",
    "    \"lower_025\",\n",
    "    \"median\",\n",
    "    \"top_025\"\n",
    "])\n",
    "\n",
    "bootstrap_df[\"total_ci\"] = bootstrap_df[\"top_025\"] - bootstrap_df[\"lower_025\"]\n",
    "bootstrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_df.to_csv(\"bootstrap_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
